# 全局用户, 自动解析当前操作用户
global_user: common
# 初始化时由用户输入本机的ip地址
local_ip: 10.0.1.160
# SSH执行命令超时时间，单位秒
ssh_cmd_timeout: 60
# SSH连通性校验超时时间，单位秒
ssh_check_timeout: 10
# 线程池最大workers
thread_pool_max_workers: 10
# redis相关配置
redis:
  host: 127.0.0.1
  port: 6380
  password: common123
# mysql相关配置
mysql:
  host: 127.0.0.1
  port: 3307
  username: common
  password: Common@123
# salt相关配置
salt_master:
  publish_port: 19004
  ret_port: 19005
  timeout: 30
# uwsgi的配置
uwsgi:
  socket: 127.0.0.1:19003
  processes: 4
  threads: 2
# tengine相关的配置
tengine:
  access_port: 19001
  runserver_port: 19002
# 登录token过期时间，天
token_expiration: 1
#grafana认证字段，无需修改
grafana_api_key: test
# 关联邮件设置,谨慎修改
alert_manager:
  # 是否开启发送邮件配置，默认不开启
  send_email: true
  # 发件人邮箱配置
  EMAIL_SEND: 123456789@qq.com
  # smtp服务器地址端口配置
  SMTP_SMARTHOST: smtp.163.com:465
  # 解释待定？？？？
  SMTP_HELLO: 163.com
  # 发件人的用户名配置
  EMAIL_SEND_USER: 123456789@qq.com
  # 发件人邮箱秘钥
  EMAIL_SEND_PASSWORD: '12345'
  # 发送频率(同一条报警消息的发送频率,s、m、h对应 秒、分、小时)
  EMAIL_SEND_INTERVAL: 30m
  # 接收代号
  RECEIVER: cloudwise
  # 收件人
  EMAIL_ADDRESS: 123@qq.com
  # webhook地址，仅在手动维护OMP各个组件时才可能用到，其他情况下不建议修改
  WEBHOOK_URL: http://127.0.0.1:19001/api/promemonitor/receiveAlert/
# prometheus basic auth
prometheus_auth:
  username: omp
  plaintext_password: Yunweiguanli@OMP_123
  ciphertext_password: $2b$12$R8WlKOEV2M9iBjEhnWQORepigbQoD1D/rAyEXwIu/aS5t94deTVDu
# 监控使用相关端口配置
monitor_port:
  # server各个端口
  prometheus: 19011
  loki: 19012
  alertmanager: 19013
  grafana: 19014
  # agent端各个端口配置
  blackboxExporter: 19015
  promtail: 19016
  nodeExporter: 19017
  processExporter: 19018
  mysqlExporter: 19019
  redisExporter: 19020
  kafkaExporter: 19021
  zookeeperExporter: 19022
  clickhouseExporter: 19023
  postgreSqlExporter: 19024
  beanstalkdExporter: 19025
  tengineExporter: 19026
  elasticsearchExporter: 19027
  httpdExporter: 19028
  igniteExporter: 19029
  # arangodb与nacos没有单独的exporter，使用的是arangodb和nacos的原生自带接口
  arangodbExporter: 18119
  nacosExporter: 18117
  monitorAgent: 19031
# Loki相关配置
loki_config:
  # promtail采集日志文件名等级过滤 [debug, info, warn, error, all]
  scrape_log_level: error

# 基础及公共组件间的等级划分，不要将自研服务类的服务放入下面的配置
# 用于控制服务安装过程中的执行顺序、服务的启停控制顺序
# 安装时顺序从小到大执行，同级别并发执行
basic_order:
  0:
    - jdk
    - safeRM
    - tengine
    - mysql
    - comLib
    - redis
    - arangodb
    - minio
    - postgreSql
    - prometheus
    - pushgateway
    - mongodb
    - nodejs
    - beanstalk
  1:
    - keepalived
    - httpd
    - elasticsearch
    - zookeeper
    - rocketmq
    - wkhtmltox
    - tomcat
    - jkbPhp
  2:
    - nacos
    - xxlJob
    - kafka
    - clickhouse
    - hadoop
  3:
    - flink
    - aopsUtils
    - filebeat


# 亲和力服务名称
# app_name 和冗余字段中 affinity 的值，二者需保持一致
affinity:
  tengine: tengine

# hadoop 角色信息
hadoop_role:
  single:
    - namenode
    - secondarynamenode
    - datanode
    - resourcemanager
    - nodemanager
  cluster:
    - namenode
    - datanode
    - resourcemanager
    - nodemanager
    - zkfc
    - journalnode

#主机名前缀
hostname_prefix: docp